{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "import io\n",
    "import itertools\n",
    "\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "EPOCHS = 20\n",
    "BUFFER_SIZE = 70_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_data, mnist_info = tfds.load('mnist', with_info=True,as_supervised=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train, mnist_test = mnist_data['train'], mnist_data['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale(image, label):\n",
    "    image = tf.cast(image,tf.float32)\n",
    "    image /=255.\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_data = mnist_train.map(scale)\n",
    "test_data = mnist_test.map(scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_size = tf.cast(.1*mnist_info.splits['train'].num_examples,tf.int64)\n",
    "test_size = tf.cast(mnist_info.splits['test'].num_examples, tf.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_data = train_val_data.shuffle(BUFFER_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_val_data.skip(val_size)\n",
    "val_data = train_val_data.take(val_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.batch(BATCH_SIZE)\n",
    "test_data = test_data.batch(test_size)\n",
    "val_data = val_data.batch(val_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting the arrays from val_data for building confusion matrix\n",
    "for images, labels in val_data:\n",
    "    image_val = images.numpy()\n",
    "    label_val = labels.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### creating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(50,5, activation='relu',input_shape =(28,28,1)),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
    "    tf.keras.layers.Conv2D(50,3, activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(10)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "________________________________________________________________________________\n",
      "Layer (type)                        Output Shape                    Param #     \n",
      "================================================================================\n",
      "conv2d_2 (Conv2D)                   (None, 24, 24, 50)              1300        \n",
      "________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)      (None, 12, 12, 50)              0           \n",
      "________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)                   (None, 10, 10, 50)              22550       \n",
      "________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)      (None, 5, 5, 50)                0           \n",
      "________________________________________________________________________________\n",
      "flatten_1 (Flatten)                 (None, 1250)                    0           \n",
      "________________________________________________________________________________\n",
      "dense_1 (Dense)                     (None, 10)                      12510       \n",
      "================================================================================\n",
      "Total params: 36,360\n",
      "Trainable params: 36,360\n",
      "Non-trainable params: 0\n",
      "________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary(line_length=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#definig loss func\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compliling the model\n",
    "model.compile(optimizer='adam', loss= loss_fn,metrics=['accuracy'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = 'logs\\\\fit\\\\'+'run-1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#return a figure of confusion matrix\n",
    "def plot_confusion_matrix(cm, class_names):\n",
    "    figure = plt.figure(figsize=(12, 12))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    plt.title(\"Confusion matrix\")\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(class_names))\n",
    "    plt.xticks(tick_marks, class_names, rotation=45)\n",
    "    plt.yticks(tick_marks, class_names)\n",
    "\n",
    "    # Normalize the confusion matrix\n",
    "    cm = np.around(cm.astype('float') / cm.sum(axis=1)[:, np.newaxis], decimals=2)\n",
    "\n",
    "    # Use white text if squares are dark; otherwise black.\n",
    "    threshold = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        color = \"white\" if cm[i, j] > threshold else \"black\"\n",
    "        plt.text(j, i, cm[i, j], horizontalalignment=\"center\", color=color)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label') \n",
    "    return figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting the matplotlib figure to png\n",
    "def plot_to_image(figure):\n",
    "    \n",
    "    #save the plot to a png in memory\n",
    "    buf = io.BytesIO()\n",
    "    plt.savefig(buf, format='png')\n",
    "    \n",
    "    #closing the figure to prevent from displaying in the notebook\n",
    "    plt.close(figure)\n",
    "    \n",
    "    buf.seek(0)\n",
    "    \n",
    "    image = tf.image.decode_png(buf.getvalue(), channels=4)\n",
    "    \n",
    "    #add the batch dimension\n",
    "    image = tf.expand_dims(image, 0)\n",
    "    \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining a file writer variable for logging\n",
    "file_writer_cm = tf.summary.create_file_writer(log_dir + '/cm')\n",
    "def log_confusion_matrix(epoch, logs):\n",
    "    #predict values for validation set\n",
    "    test_pred_r = model.predict(image_val)\n",
    "    test_pred = np.argmax(test_pred_r, axis=1)\n",
    "    \n",
    "    cm = metrics.confusion_matrix(label_val, test_pred)\n",
    "    \n",
    "    figure = plot_confusion_matrix(cm, class_names=['0','1','2','3','4','5','6','7','8','9'])\n",
    "    cm_image = plot_to_image(figure)\n",
    "    \n",
    "    #log the confusion matrix as image summary\n",
    "    with file_writer_cm.as_default():\n",
    "        tf.summary.image('Confusion Matrix', cm_image, step=epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining callbacks\n",
    "cm_callback = tf.keras.callbacks.LambdaCallback(on_epoch_end=log_confusion_matrix)\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir =log_dir, histogram_freq = 1, profile_batch =0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#early stopping callback\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    mode = 'auto',\n",
    "    min_delta = 0,\n",
    "    patience= 2,\n",
    "    verbose = 0,\n",
    "    restore_best_weights= True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "422/422 - 26s - loss: 0.2861 - accuracy: 0.9174 - val_loss: 0.0905 - val_accuracy: 0.9733\n",
      "Epoch 2/20\n",
      "422/422 - 25s - loss: 0.0726 - accuracy: 0.9785 - val_loss: 0.0483 - val_accuracy: 0.9858\n",
      "Epoch 3/20\n",
      "422/422 - 25s - loss: 0.0541 - accuracy: 0.9841 - val_loss: 0.0613 - val_accuracy: 0.9828\n",
      "Epoch 4/20\n",
      "422/422 - 26s - loss: 0.0449 - accuracy: 0.9864 - val_loss: 0.0299 - val_accuracy: 0.9907\n",
      "Epoch 5/20\n",
      "422/422 - 25s - loss: 0.0367 - accuracy: 0.9886 - val_loss: 0.0288 - val_accuracy: 0.9903\n",
      "Epoch 6/20\n",
      "422/422 - 26s - loss: 0.0324 - accuracy: 0.9902 - val_loss: 0.0249 - val_accuracy: 0.9928\n",
      "Epoch 7/20\n",
      "422/422 - 26s - loss: 0.0286 - accuracy: 0.9914 - val_loss: 0.0275 - val_accuracy: 0.9917\n",
      "Epoch 8/20\n",
      "422/422 - 26s - loss: 0.0228 - accuracy: 0.9925 - val_loss: 0.0182 - val_accuracy: 0.9942\n",
      "Epoch 9/20\n",
      "422/422 - 25s - loss: 0.0216 - accuracy: 0.9930 - val_loss: 0.0188 - val_accuracy: 0.9945\n",
      "Epoch 10/20\n",
      "422/422 - 25s - loss: 0.0185 - accuracy: 0.9942 - val_loss: 0.0126 - val_accuracy: 0.9957\n",
      "Epoch 11/20\n",
      "422/422 - 25s - loss: 0.0163 - accuracy: 0.9945 - val_loss: 0.0157 - val_accuracy: 0.9953\n",
      "Epoch 12/20\n",
      "422/422 - 26s - loss: 0.0145 - accuracy: 0.9953 - val_loss: 0.0125 - val_accuracy: 0.9955\n",
      "Epoch 13/20\n",
      "422/422 - 26s - loss: 0.0138 - accuracy: 0.9953 - val_loss: 0.0200 - val_accuracy: 0.9930\n",
      "Epoch 14/20\n",
      "422/422 - 25s - loss: 0.0111 - accuracy: 0.9963 - val_loss: 0.0059 - val_accuracy: 0.9988\n",
      "Epoch 15/20\n",
      "422/422 - 26s - loss: 0.0102 - accuracy: 0.9966 - val_loss: 0.0117 - val_accuracy: 0.9978\n",
      "Epoch 16/20\n",
      "422/422 - 26s - loss: 0.0078 - accuracy: 0.9975 - val_loss: 0.0049 - val_accuracy: 0.9983\n",
      "Epoch 17/20\n",
      "422/422 - 25s - loss: 0.0073 - accuracy: 0.9979 - val_loss: 0.0063 - val_accuracy: 0.9973\n",
      "Epoch 18/20\n",
      "422/422 - 26s - loss: 0.0071 - accuracy: 0.9977 - val_loss: 0.0102 - val_accuracy: 0.9972\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x23c6886e070>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    train_data,\n",
    "    epochs=EPOCHS,\n",
    "    verbose=2,\n",
    "    callbacks=[tensorboard_callback,cm_callback,early_stopping],\n",
    "    validation_data= val_data,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualisingin Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-8dfe6a52ef4af97d\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-8dfe6a52ef4af97d\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir 'logs/fit'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
