{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing necessary packages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading and preprocessing the data\n",
    "##### Steps involed in preprocessing of MNIST\n",
    "1- determining the hyperparams/constants <br>\n",
    "2- scaling the data <br>\n",
    "3- defining the size of validation dataset <br>\n",
    "4- shuffling the data <br>\n",
    "5- seperating te train and validation datasets <br>\n",
    "6- batching the datasets <br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining some constants/hyperparameters\n",
    "BUFFER_SIZE = 70_000 # for reshuffling\n",
    "BATCH_SIZE = 128\n",
    "NUM_EPOCHS = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with_info returns the meta info about the dataset\n",
    "mnist_data, mnist_info = tfds.load(name=\"mnist\", as_supervised=True,with_info=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train, mnist_test = mnist_data['train'],mnist_data['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining the scale function to scale data between 0 and 1\n",
    "def scale(image, label):\n",
    "    image = tf.cast(image,tf.float32)\n",
    "    image /= 255.\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaling data by applying the function on the train and test data \n",
    "mnist_train_validation = mnist_train.map(scale)\n",
    "test_data = mnist_test.map(scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(6000, shape=(), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "#defining the size of validation set\n",
    "validation_size = tf.cast(.1 * mnist_info.splits['train'].num_examples, tf.int64)\n",
    "print(validation_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(10000, shape=(), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "#defining the size of test set\n",
    "test_size = tf.cast(mnist_info.splits['test'].num_examples,tf.int64)\n",
    "print(test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reshuffling the dataset\n",
    "mnist_train_validation = mnist_train_validation.shuffle(BUFFER_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the train and validation datasets\n",
    "#\n",
    "train_data = mnist_train_validation.skip(validation_size)\n",
    "validation_data = mnist_train_validation.take(validation_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#batching the data\n",
    "train_data = train_data.batch(BATCH_SIZE)\n",
    "validation_data = validation_data.batch(validation_size)\n",
    "test_data = test_data.batch(test_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating the CNN model\n",
    "the model architecture will be CONV-> MAXPOOL-> CONV-> MAXPOOL-> FLATTEN-> DENSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(50, 5, activation = 'relu', input_shape=(28,28,1)),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size =(2,2)),\n",
    "    tf.keras.layers.Conv2D(50,3, activation = 'relu'),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size = (2,2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(10) # 10 digits to recognize\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "________________________________________________________________________________\n",
      "Layer (type)                        Output Shape                    Param #     \n",
      "================================================================================\n",
      "conv2d_2 (Conv2D)                   (None, 24, 24, 50)              1300        \n",
      "________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)      (None, 12, 12, 50)              0           \n",
      "________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)                   (None, 10, 10, 50)              22550       \n",
      "________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)      (None, 5, 5, 50)                0           \n",
      "________________________________________________________________________________\n",
      "flatten_1 (Flatten)                 (None, 1250)                    0           \n",
      "________________________________________________________________________________\n",
      "dense_1 (Dense)                     (None, 10)                      12510       \n",
      "================================================================================\n",
      "Total params: 36,360\n",
      "Trainable params: 36,360\n",
      "Non-trainable params: 0\n",
      "________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#summary of the model\n",
    "model.summary(line_length=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#incorporating the softmax into loss function\n",
    "#when using the softmax activation, the loss can rarely be unstable\n",
    "# use a loss calculation that automatically corrects for the missing softmax\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compliling the model\n",
    "model.compile(optimizer='adam',loss=loss_fn, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining early stoping\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    min_delta= 0,\n",
    "    mode = 'auto',\n",
    "    patience = 2,\n",
    "    verbose = 2,\n",
    "    restore_best_weights = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "422/422 - 25s - loss: 0.0703 - accuracy: 0.9789 - val_loss: 0.0581 - val_accuracy: 0.9818\n",
      "Epoch 2/20\n",
      "422/422 - 26s - loss: 0.0513 - accuracy: 0.9845 - val_loss: 0.0361 - val_accuracy: 0.9895\n",
      "Epoch 3/20\n",
      "422/422 - 25s - loss: 0.0396 - accuracy: 0.9880 - val_loss: 0.0418 - val_accuracy: 0.9863\n",
      "Epoch 4/20\n",
      "422/422 - 26s - loss: 0.0355 - accuracy: 0.9892 - val_loss: 0.0313 - val_accuracy: 0.9905\n",
      "Epoch 5/20\n",
      "422/422 - 26s - loss: 0.0310 - accuracy: 0.9901 - val_loss: 0.0237 - val_accuracy: 0.9932\n",
      "Epoch 6/20\n",
      "422/422 - 26s - loss: 0.0260 - accuracy: 0.9923 - val_loss: 0.0178 - val_accuracy: 0.9947\n",
      "Epoch 7/20\n",
      "422/422 - 25s - loss: 0.0231 - accuracy: 0.9928 - val_loss: 0.0161 - val_accuracy: 0.9960\n",
      "Epoch 8/20\n",
      "422/422 - 26s - loss: 0.0204 - accuracy: 0.9938 - val_loss: 0.0205 - val_accuracy: 0.9940\n",
      "Epoch 9/20\n",
      "422/422 - 26s - loss: 0.0175 - accuracy: 0.9943 - val_loss: 0.0190 - val_accuracy: 0.9932\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00009: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x18b5900ca90>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train the network\n",
    "model.fit(\n",
    "    train_data,\n",
    "    epochs= NUM_EPOCHS,\n",
    "    validation_data= validation_data,\n",
    "    callbacks= [early_stopping],\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step - loss: 0.0275 - accuracy: 0.9907\n"
     ]
    }
   ],
   "source": [
    "#evaluate returns the loss and metrics\n",
    "test_loss, test_accuracy = model.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss:  0.0275. test accuracy:  99.07%\n"
     ]
    }
   ],
   "source": [
    "print('test loss: {0: .4f}. test accuracy: {1: .2f}%'.format(test_loss, test_accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting images and results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seperating test iamages and their labels into 2 arrays\n",
    "for images, labels in test_data:\n",
    "    images_test = images.numpy()\n",
    "    labels_test = labels.numpy()\n",
    "#reshaping the images for plotting\n",
    "images_reshape = np.reshape(images_test,(10000,28,28))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAH4AAAB7CAYAAACy7jQ7AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAD/0lEQVR4nO2dzSstcRyH77koTnnJygKrs5KUJEWksJDsRPEPeCn5FxQrWUmytxE2koUSJWEhZYWVLCyQl1Lyeu7mLu7nO93fuefOyPx8Ps/u6Zw551dP0/fMjBmJdDr9Q/Dx86sXIL4GhSdF4UlReFIUnhSFJyXX9WIikdCxnsek0+nE317THk+KwpOi8KQoPCkKT4rCk6LwpCg8KQpPisKTovCkKDwpCk+KwpOi8KQoPCkKT4rCk6LwpCg8KQpPisKTovCkKDwpCk+KwpOi8KQoPCkKT4rCk+K8TVpES0FBAXhbW5vz/U9PT+Cbm5uRrUV7PCkKT4rCk+LVjM/JyQGfmJgA7+vrc25vZ6Td/uLiAjzTUz/teqyPj4+D9/f3g5eXlzs//+3tDXxvbw+8t7cX/Orqyvl5f6I9nhSFJ0XhSUm45thXP+6ssLAQfGlpCbyjoyPS7xsdHQU/OTkB7+npAa+vrwevra2NdD3ZYn9j6HFnIoDCk6LwpMRqxldUVICvra2BV1dXO7e/vLwEHxoaAm9oaAAfHBwELy0t/ad1RsXBwQH49PQ0+O3tbVaft7W1Ba4ZLwIoPCkKT0qsZvzGxgZ4puvVdqZ3dXWBHx8fO7ff2dkBb2xszLREJ8/Pz+ALCwvgk5OT4Pbcur3+HhbNeBFA4UlReFJidT2+vb0d3P7+eH9/d77/9PT0cxb2m7u7O/DFxUXwqakp8PPz809dTxi0x5Oi8KTE6nDOruXj4wP89fUVPD8/P9T31dTUgI+NjYE/PDyAz83NgZ+dnYX6/s9Gh3MigMKTovCkxGrGz8zMgA8PDzvfPzIyAm5PkT4+PkazME/RjBcBFJ4UhSclVjO+qKgIfHl5GTzTZdrt7W3wzs5O8JeXl/9fnIdoxosACk+KwpMSqxlvKSkpAV9ZWQFvbW11br+/vw/e1NQUxbK8QTNeBFB4UhSelFjPeEsymQRfX18Hb25udm4/Pz8Pbq+/f7fjfM14EUDhSVF4Urya8Zbi4mJw+6iUTOf2W1pawHd3d6NZWEzQjBcBFJ4UhSfF6xlvqaurA7fX5+15gNnZWXD7uDPf0YwXARSeFIUnJVa3SYfl8PAQ/P7+HtzO+MrKSnD7SFB7W/Z3Qns8KQpPisKT4tWMz83F5dr71e0jQjM9orS7u9v5/uvr62yX6A3a40lReFIUnhSvztXbGX90dAReVVUV6vPLysrAfZ/xOlcvAig8KV4dztn/vGj/tGpgYAA8Ly8PPJVKga+uroLf3NyEXaI3aI8nReFJUXhSvDqcE9mhwzkRQOFJUXhSFJ4UhSdF4UlReFIUnhSFJ0XhSVF4Upzn6sX3RXs8KQpPisKTovCkKDwpCk/KL7SLIw7/kNoRAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 144x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label: 5\n"
     ]
    }
   ],
   "source": [
    "#read an image and display it\n",
    "i = 502\n",
    "plt.figure(figsize=(2,2))\n",
    "plt.axis('off')\n",
    "plt.imshow(images_reshape[i-1], cmap='gray', aspect='auto')\n",
    "plt.show()\n",
    "print('label: {}'.format(labels_test[i-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -5.889513 , -18.7005   , -18.572338 ,  -5.1432576,  -1.1506456,\n",
       "          3.3093624,  -8.684445 ,  -1.2828286,   5.9344115,  -2.128931 ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#obtain model preds\n",
    "predictions = model.predict(images_test[i-1:i])\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.8200979e-04, 1.8622992e-09, 2.1169453e-09, 1.4384191e-03,\n",
       "        7.7956930e-02, 6.7423553e+00, 4.1683801e-05, 6.8304345e-02,\n",
       "        9.3079918e+01, 2.9308299e-02]], dtype=float32)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#converting predictions into probabilities\n",
    "prob = tf.nn.softmax(predictions).numpy()\n",
    "prob = prob *100\n",
    "prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 10 artists>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plotting the probabilities for each class for the image i\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.bar(x = [0,1,2,3,4,5,6,7,8,9], height= prob[0], tick_label = [\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\"] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
